### Focus on Python for Data Engineering

#### Extract, Transform, Load (ETL) in Python:

##### Data Extraction:
- **Pandas:** Read data from CSV, Excel, SQL databases, and more.
- **SQLAlchemy:** Connect and extract data from relational databases.
- **Requests/BeautifulSoup:** Extract data from web APIs or scrape websites.

##### Data Transformation:
- **Pandas:** Clean, manipulate, and transform data.
- **NumPy:** Perform numerical operations on data.
- **PySpark:** Process large datasets using Spark's Python API (useful for big data).

##### Data Loading:
- **Pandas/SQLAlchemy:** Write data back to relational databases.
- **Boto3:** Interact with AWS services to load data into S3, Redshift, etc.

### Tools and Libraries for Data Engineering:

#### Data Extraction:
- **Pandas, Reading and Filtering Data:**
  - `pd.read_csv()`
  - `pd.read_sql()`
- **SQLAlchemy:**
  - `create_engine()`
  - `engine.execute()`
- **Requests, API learning:**
  - `requests.get()`
  - `response.json()`

#### Data Transformation:
- **Pandas, Preprocessing and cleaning:**
  - `df.groupby()`
  - `df.merge()`
  - `df.apply()`
- **NumPy, various statistics analysis:**
  - `np.array()`
  - `np.mean()`
  - `np.sum()`
- **PySpark:**
  - `spark.read()`
  - `df.withColumn()`
  - `df.filter()`

#### Data Loading:
- **Pandas, exporting for reports, plugging  back into Excel:**
  - `df.to_csv()`
  - `df.to_sql()`
- **SQLAlchemy:**
  - `Table.insert()`
  - `engine.execute()`
- **Boto3:**
  - `s3_client.upload_file()`
  - `redshift.execute()`

### Key Concepts:
- **Data Modeling:** Understanding relational database schema design, normalization, and data warehousing concepts.
- **ETL Process:** Knowing how to design, implement, and manage ETL workflows, ensuring data quality and integrity.
- **AWS Fundamentals:** Familiarity with core AWS services like S3, EC2, and IAM, as well as data-specific services like Redshift and Glue.

# Deeper articles, more narrow views 
